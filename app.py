# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JjkxUiaHJbcIiZV0V4cl1T2vSsVz761p
"""

# app.py
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
import pyswarms as ps
from pyswarms.single.global_best import GlobalBestPSO
import io
import time

# Set page config
st.set_page_config(
    page_title="Stock Prediction LSTM-PSO",
    page_icon="ðŸ“ˆ",
    layout="wide"
)

# Initialize session state
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False

# Configuration constants
BASE_UNITS = 16
BASE_DROPOUT = 0.01
BASE_BATCH = 16
BASE_EPOCHS = 10
BASE_LR = 1e-3

PSO_N_PARTICLES = 10
PSO_ITERS = 10
PSO_OPTIONS = {'c1': 1.5, 'c2': 1.5, 'w': 0.5}
PSO_BOUNDS = (
    [8, 1e-5, 8, 0.0],
    [128, 1e-1, 128, 0.3]
)

def set_seed(s=42):
    np.random.seed(s)
    tf.random.set_seed(s)

def compute_mape(y_true, y_pred):
    y_true = np.array(y_true).astype(float)
    y_pred = np.array(y_pred).astype(float)
    mask = y_true != 0
    if np.any(mask):
        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0
    else:
        return np.nan

def build_lstm_model(input_shape, units=16, dropout=0.01, lr=1e-3):
    K.clear_session()
    model = Sequential()
    model.add(LSTM(units=units, input_shape=input_shape))
    if dropout > 0:
        model.add(Dropout(dropout))
    model.add(Dense(1, activation='linear'))
    model.compile(optimizer=Adam(learning_rate=lr), loss='mse')
    return model

def make_sequences(X_scaled, y_scaled, window):
    X_seq, y_seq = [], []
    for i in range(window, len(X_scaled)):
        X_seq.append(X_scaled[i-window:i])
        y_seq.append(y_scaled[i])
    X_seq = np.array(X_seq)
    y_seq = np.array(y_seq)
    return X_seq, y_seq

def load_sample_data():
    """Load sample data for demonstration"""
    try:
        # Download sample data
        ticker = "TLKM.JK"
        end_date = pd.Timestamp.now()
        start_date = end_date - pd.DateOffset(months=24)
        df = yf.download(ticker, start=start_date, end=end_date)
        return df
    except:
        # Fallback: create sample data
        dates = pd.date_range(start='2020-01-01', end='2024-01-01', freq='D')
        np.random.seed(42)
        prices = 4000 + np.cumsum(np.random.randn(len(dates)) * 50)
        df = pd.DataFrame({'Close': prices}, index=dates)
        return df

def main():
    st.title("ðŸ“ˆ Stock Price Prediction with LSTM-PSO")
    st.markdown("Prediksi harga saham menggunakan model LSTM yang dioptimasi dengan Particle Swarm Optimization")

    # Sidebar
    st.sidebar.header("Configuration")

    # Data source selection
    data_source = st.sidebar.radio(
        "Data Source",
        ["Upload Excel File", "Yahoo Finance Ticker", "Use Sample Data"]
    )

    df = None

    if data_source == "Upload Excel File":
        uploaded_file = st.sidebar.file_uploader("Upload Excel File", type=['xlsx'])
        if uploaded_file:
            df = pd.read_excel(uploaded_file)
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date')
                df.set_index('Date', inplace=True)

    elif data_source == "Yahoo Finance Ticker":
        ticker = st.sidebar.text_input("Stock Ticker", "TLKM.JK")
        if st.sidebar.button("Download Data"):
            with st.spinner("Downloading data..."):
                try:
                    df = yf.download(ticker, period="2y")
                    st.sidebar.success(f"Data for {ticker} downloaded successfully!")
                except Exception as e:
                    st.sidebar.error(f"Error downloading data: {e}")

    else:  # Use Sample Data
        if st.sidebar.button("Load Sample Data"):
            with st.spinner("Loading sample data..."):
                df = load_sample_data()
                st.sidebar.success("Sample data loaded successfully!")

    # Display data if loaded
    if df is not None and not df.empty:
        st.session_state.data_loaded = True

        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("Data Preview")
            st.dataframe(df.head(), use_container_width=True)

            # Plot original data
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.plot(df.index, df['Close'], label='Close Price', linewidth=1)
            ax.set_title("Stock Price Time Series")
            ax.set_xlabel("Date")
            ax.set_ylabel("Price")
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

        with col2:
            st.subheader("Data Info")
            st.write(f"**Period:** {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}")
            st.write(f"**Total Records:** {len(df)}")
            st.write(f"**Missing Values:** {df['Close'].isnull().sum()}")

            # Basic statistics
            st.write("**Statistics:**")
            st.write(f"Mean: {df['Close'].mean():.2f}")
            st.write(f"Std: {df['Close'].std():.2f}")
            st.write(f"Min: {df['Close'].min():.2f}")
            st.write(f"Max: {df['Close'].max():.2f}")

        # Model training section
        st.markdown("---")
        st.header("Model Training")

        training_col1, training_col2 = st.columns([1, 1])

        with training_col1:
            st.subheader("Training Configuration")
            lookback_days = st.slider("Lookback Days", 1, 60, 1)
            train_test_split = st.slider("Train-Test Split (%)", 70, 90, 80)
            run_pso = st.checkbox("Enable PSO Optimization", value=True)

            if st.button("Train Model", type="primary"):
                with st.spinner("Training model... This may take several minutes"):
                    try:
                        # Preprocessing
                        feature_cols = ["Close"]
                        target_col = "Close"

                        data_features = df[feature_cols].values
                        data_target = df[[target_col]].values

                        n = len(df)
                        n_train = int(n * (train_test_split / 100))
                        n_test = n - n_train

                        # Fit scalers on training data only
                        scaler_X = MinMaxScaler().fit(data_features[:n_train])
                        scaler_y = MinMaxScaler().fit(data_target[:n_train])

                        Xs = scaler_X.transform(data_features)
                        ys = scaler_y.transform(data_target)

                        # Create sequences
                        X_seq_all, y_seq_all = make_sequences(Xs, ys, window=lookback_days)
                        train_end_idx = n_train - lookback_days

                        if train_end_idx <= 0:
                            st.error("Lookback window too large for training data. Please reduce lookback days.")
                            return

                        X_train = X_seq_all[:train_end_idx]
                        y_train = y_seq_all[:train_end_idx]
                        X_test = X_seq_all[train_end_idx:]
                        y_test = y_seq_all[train_end_idx:]

                        # Store in session state
                        st.session_state.X_train = X_train
                        st.session_state.y_train = y_train
                        st.session_state.X_test = X_test
                        st.session_state.y_test = y_test
                        st.session_state.scaler_X = scaler_X
                        st.session_state.scaler_y = scaler_y
                        st.session_state.lookback_days = lookback_days

                        # Baseline model
                        st.subheader("Baseline LSTM Model")
                        progress_bar = st.progress(0)

                        set_seed(42)
                        model_base = build_lstm_model(
                            input_shape=(X_train.shape[1], X_train.shape[2]),
                            units=BASE_UNITS,
                            dropout=BASE_DROPOUT,
                            lr=BASE_LR
                        )

                        # Train baseline model
                        history_base = model_base.fit(
                            X_train, y_train,
                            epochs=BASE_EPOCHS,
                            batch_size=BASE_BATCH,
                            validation_split=0.2,
                            verbose=0
                        )

                        progress_bar.progress(50)

                        # Evaluate baseline
                        y_pred_scaled_base = model_base.predict(X_test, verbose=0)
                        y_pred_base = scaler_y.inverse_transform(y_pred_scaled_base).flatten()
                        y_true_base = scaler_y.inverse_transform(y_test).flatten()

                        mse_base = mean_squared_error(y_true_base, y_pred_base)
                        mape_base = compute_mape(y_true_base, y_pred_base)

                        st.session_state.baseline_results = {
                            'mse': mse_base,
                            'mape': mape_base,
                            'predictions': y_pred_base,
                            'actual': y_true_base
                        }

                        st.success("Baseline model trained successfully!")

                        if run_pso:
                            st.subheader("PSO Optimization")
                            pso_progress = st.progress(0)

                            # PSO objective function
                            def make_pso_obj(X_tr, y_tr, X_va, y_va, scaler_y):
                                def obj_fn(particles):
                                    n_particles = particles.shape[0]
                                    costs = np.zeros(n_particles)

                                    for i, p in enumerate(particles):
                                        units = int(np.round(p[0]))
                                        lr = float(p[1])
                                        batch = int(np.round(p[2]))
                                        dropout = float(p[3])

                                        units = max(8, min(units, 128))
                                        lr = max(1e-8, min(lr, 1e-1))
                                        batch = max(1, min(batch, 128))
                                        dropout = max(0.0, min(dropout, 0.3))

                                        try:
                                            set_seed(42)
                                            K.clear_session()

                                            model = build_lstm_model(
                                                input_shape=(X_tr.shape[1], X_tr.shape[2]),
                                                units=units,
                                                dropout=dropout,
                                                lr=lr
                                            )

                                            model.fit(
                                                X_tr, y_tr,
                                                epochs=5,
                                                batch_size=batch,
                                                validation_data=(X_va, y_va),
                                                verbose=0
                                            )

                                            yv_pred = model.predict(X_va, verbose=0)
                                            yv_pred_orig = scaler_y.inverse_transform(yv_pred).flatten()
                                            yv_true_orig = scaler_y.inverse_transform(y_va).flatten()

                                            costs[i] = mean_squared_error(yv_true_orig, yv_pred_orig)

                                        except Exception as e:
                                            costs[i] = 1e12

                                        K.clear_session()

                                    return costs
                                return obj_fn

                            # Prepare PSO data
                            val_frac_for_pso = 0.2
                            n_tr_samples = X_train.shape[0]
                            n_tr_val = int(n_tr_samples * (1 - val_frac_for_pso))

                            X_tr_for_pso = X_train[:n_tr_val]
                            y_tr_for_pso = y_train[:n_tr_val]
                            X_val_for_pso = X_train[n_tr_val:]
                            y_val_for_pso = y_train[n_tr_val:]

                            pso_obj = make_pso_obj(
                                X_tr_for_pso, y_tr_for_pso,
                                X_val_for_pso, y_val_for_pso,
                                scaler_y
                            )

                            # Run PSO
                            optimizer = GlobalBestPSO(
                                n_particles=PSO_N_PARTICLES,
                                dimensions=4,
                                options=PSO_OPTIONS,
                                bounds=PSO_BOUNDS
                            )

                            # Manual PSO loop with progress updates
                            history_gbest_cost = []

                            for it in range(PSO_ITERS):
                                costs = pso_obj(optimizer.swarm.position)

                                # Update best positions
                                mask = costs < optimizer.swarm.pbest_cost
                                optimizer.swarm.pbest_cost[mask] = costs[mask]
                                optimizer.swarm.pbest_pos[mask] = optimizer.swarm.position[mask].copy()

                                best_idx = np.argmin(optimizer.swarm.pbest_cost)
                                optimizer.swarm.best_cost = optimizer.swarm.pbest_cost[best_idx]
                                optimizer.swarm.best_pos = optimizer.swarm.pbest_pos[best_idx].copy()

                                history_gbest_cost.append(float(optimizer.swarm.best_cost))

                                # Update PSO
                                r1 = np.random.rand(*optimizer.swarm.position.shape)
                                r2 = np.random.rand(*optimizer.swarm.position.shape)
                                optimizer.swarm.velocity = (
                                    PSO_OPTIONS['w'] * optimizer.swarm.velocity
                                    + PSO_OPTIONS['c1'] * r1 * (optimizer.swarm.pbest_pos - optimizer.swarm.position)
                                    + PSO_OPTIONS['c2'] * r2 * (optimizer.swarm.best_pos - optimizer.swarm.position)
                                )
                                optimizer.swarm.position += optimizer.swarm.velocity

                                lb, ub = np.array(PSO_BOUNDS[0]), np.array(PSO_BOUNDS[1])
                                optimizer.swarm.position = np.clip(optimizer.swarm.position, lb, ub)

                                pso_progress.progress((it + 1) / PSO_ITERS)

                            best_pos = optimizer.swarm.best_pos
                            best_units = int(np.round(best_pos[0]))
                            best_lr = float(best_pos[1])
                            best_batch = int(np.round(best_pos[2]))
                            best_dropout = float(best_pos[3])

                            st.session_state.pso_results = {
                                'best_units': best_units,
                                'best_lr': best_lr,
                                'best_batch': best_batch,
                                'best_dropout': best_dropout,
                                'best_cost': history_gbest_cost[-1],
                                'convergence': history_gbest_cost
                            }

                            # Train final model with PSO parameters
                            st.subheader("Final PSO-LSTM Model")
                            final_progress = st.progress(0)

                            set_seed(42)
                            model_final = build_lstm_model(
                                input_shape=(X_train.shape[1], X_train.shape[2]),
                                units=best_units,
                                dropout=best_dropout,
                                lr=best_lr
                            )

                            history_final = model_final.fit(
                                X_train, y_train,
                                epochs=100,
                                batch_size=best_batch,
                                validation_split=0.2,
                                callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)],
                                verbose=0
                            )

                            final_progress.progress(100)

                            # Evaluate final model
                            y_pred_scaled_final = model_final.predict(X_test, verbose=0)
                            y_pred_final = scaler_y.inverse_transform(y_pred_scaled_final).flatten()
                            y_true_final = scaler_y.inverse_transform(y_test).flatten()

                            mse_final = mean_squared_error(y_true_final, y_pred_final)
                            mape_final = compute_mape(y_true_final, y_pred_final)

                            st.session_state.final_results = {
                                'mse': mse_final,
                                'mape': mape_final,
                                'predictions': y_pred_final,
                                'actual': y_true_final,
                                'history': history_final.history,
                                'model': model_final
                            }

                            st.session_state.model_trained = True
                            st.success("PSO-LSTM model trained successfully!")

                    except Exception as e:
                        st.error(f"Error during training: {str(e)}")

        with training_col2:
            if st.session_state.get('model_trained', False):
                st.subheader("Training Results")

                # Display metrics
                baseline_results = st.session_state.baseline_results
                col_metric1, col_metric2 = st.columns(2)

                with col_metric1:
                    st.metric("Baseline MSE", f"{baseline_results['mse']:.6f}")
                    st.metric("Baseline MAPE", f"{baseline_results['mape']:.4f}%")

                if 'final_results' in st.session_state:
                    final_results = st.session_state.final_results
                    pso_results = st.session_state.pso_results

                    with col_metric2:
                        st.metric("PSO-LSTM MSE", f"{final_results['mse']:.6f}")
                        st.metric("PSO-LSTM MAPE", f"{final_results['mape']:.4f}%")

                    # Improvement
                    impr_mse = (baseline_results['mse'] - final_results['mse']) / baseline_results['mse'] * 100
                    impr_mape = (baseline_results['mape'] - final_results['mape']) / baseline_results['mape'] * 100

                    st.info(f"Improvement: MSE â†“ {impr_mse:.2f}%, MAPE â†“ {impr_mape:.2f}%")

                    # PSO parameters
                    st.subheader("PSO Optimized Parameters")
                    st.write(f"**Units:** {pso_results['best_units']}")
                    st.write(f"**Learning Rate:** {pso_results['best_lr']:.6f}")
                    st.write(f"**Batch Size:** {pso_results['best_batch']}")
                    st.write(f"**Dropout:** {pso_results['best_dropout']:.4f}")

        # Results visualization
        if st.session_state.get('model_trained', False):
            st.markdown("---")
            st.header("Results Visualization")

            tab1, tab2, tab3 = st.tabs(["Predictions", "Training History", "Forecast"])

            with tab1:
                fig, ax = plt.subplots(figsize=(12, 6))
                actual = st.session_state.baseline_results['actual']

                ax.plot(actual, label='Actual', linewidth=2, color='blue')
                ax.plot(st.session_state.baseline_results['predictions'],
                       label='Baseline LSTM', linewidth=2, color='red', linestyle='--')

                if 'final_results' in st.session_state:
                    ax.plot(st.session_state.final_results['predictions'],
                           label='PSO-LSTM', linewidth=2, color='orange')

                ax.set_title("Actual vs Predicted Prices")
                ax.set_xlabel("Time Index")
                ax.set_ylabel("Price")
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)

            with tab2:
                if 'final_results' in st.session_state:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

                    # Baseline training history
                    ax1.plot(st.session_state.baseline_results.get('history', {}).get('loss', []),
                            label='Training Loss')
                    ax1.plot(st.session_state.baseline_results.get('history', {}).get('val_loss', []),
                            label='Validation Loss')
                    ax1.set_title("Baseline LSTM Training History")
                    ax1.set_xlabel("Epoch")
                    ax1.set_ylabel("Loss")
                    ax1.legend()
                    ax1.grid(True, alpha=0.3)

                    # PSO-LSTM training history
                    ax2.plot(st.session_state.final_results['history']['loss'],
                            label='Training Loss')
                    ax2.plot(st.session_state.final_results['history']['val_loss'],
                            label='Validation Loss')
                    ax2.set_title("PSO-LSTM Training History")
                    ax2.set_xlabel("Epoch")
                    ax2.set_ylabel("Loss")
                    ax2.legend()
                    ax2.grid(True, alpha=0.3)

                    st.pyplot(fig)

            with tab3:
                if 'final_results' in st.session_state:
                    st.subheader("Future Price Forecast")
                    n_forecast = st.slider("Days to Forecast", 1, 30, 5)

                    if st.button("Generate Forecast"):
                        with st.spinner("Generating forecast..."):
                            try:
                                model_final = st.session_state.final_results['model']
                                scaler_X = st.session_state.scaler_X
                                scaler_y = st.session_state.scaler_y
                                lookback_days = st.session_state.lookback_days
                                data_features = df[['Close']].values

                                # Prepare last window
                                last_window_raw = data_features[-lookback_days:]
                                last_window_scaled = scaler_X.transform(last_window_raw).reshape(1, lookback_days, 1)

                                # Generate forecast
                                forecast_scaled = []
                                curr_input = last_window_scaled.copy()

                                for i in range(n_forecast):
                                    pred_s = model_final.predict(curr_input, verbose=0)[0,0]
                                    forecast_scaled.append(pred_s)
                                    new_step = np.array(pred_s).reshape(1,1,1)
                                    curr_input = np.concatenate([curr_input[:,1:,:], new_step], axis=1)

                                # Inverse transform
                                forecast_scaled_arr = np.array(forecast_scaled).reshape(-1,1)
                                forecast_inv = scaler_y.inverse_transform(forecast_scaled_arr).flatten()

                                # Create future dates
                                last_date = df.index[-1]
                                future_dates = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=n_forecast)

                                # Display forecast
                                forecast_df = pd.DataFrame({
                                    'Date': future_dates,
                                    'Forecasted Price': forecast_inv
                                })

                                st.dataframe(forecast_df.style.format({'Forecasted Price': '{:.2f}'}))

                                # Plot forecast
                                fig, ax = plt.subplots(figsize=(12, 6))

                                # Historical data (last 100 days)
                                historical_dates = df.index[-100:]
                                historical_prices = df['Close'].values[-100:]

                                ax.plot(historical_dates, historical_prices,
                                       label='Historical', color='steelblue', linewidth=2)
                                ax.plot(future_dates, forecast_inv,
                                       label='Forecast', color='orange', marker='o', linewidth=2)

                                # Connecting line
                                ax.plot([historical_dates[-1], future_dates[0]],
                                       [historical_prices[-1], forecast_inv[0]],
                                       color='orange', linestyle='--', alpha=0.7)

                                ax.set_title(f"{n_forecast}-Day Price Forecast")
                                ax.set_xlabel("Date")
                                ax.set_ylabel("Price")
                                ax.legend()
                                ax.grid(True, alpha=0.3)
                                plt.xticks(rotation=45)
                                st.pyplot(fig)

                            except Exception as e:
                                st.error(f"Error generating forecast: {str(e)}")

    else:
        st.info("ðŸ‘ˆ Please load data using the sidebar options to get started.")

        # Quick start guide
        st.markdown("---")
        st.subheader("Quick Start Guide")

        col_guide1, col_guide2, col_guide3 = st.columns(3)

        with col_guide1:
            st.write("**1. Choose Data Source**")
            st.write("Upload Excel file or use Yahoo Finance")

        with col_guide2:
            st.write("**2. Configure Model**")
            st.write("Set lookback days and training parameters")

        with col_guide3:
            st.write("**3. Train & Predict**")
            st.write("Run training and view predictions")

if __name__ == "__main__":
    main()