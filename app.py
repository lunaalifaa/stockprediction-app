# -*- coding: utf-8 -*-
"""Stock Prediction LSTM-PSO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JjkxUiaHJbcIiZV0V4cl1T2vSsVz761p
"""

# app.py
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
import pyswarms as ps
from pyswarms.single.global_best import GlobalBestPSO
import io
import time

# Set page config
st.set_page_config(
    page_title="Stock Prediction LSTM-PSO",
    page_icon="üìà",
    layout="wide"
)

# Initialize session state
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False

# Configuration constants
BASE_UNITS = 16
BASE_DROPOUT = 0.01
BASE_BATCH = 16
BASE_EPOCHS = 10
BASE_LR = 1e-3

PSO_N_PARTICLES = 10
PSO_ITERS = 10
PSO_OPTIONS = {'c1': 1.5, 'c2': 1.5, 'w': 0.5}
PSO_BOUNDS = (
    [8, 1e-5, 8, 0.0],
    [128, 1e-1, 128, 0.3]
)

def set_seed(s=42):
    np.random.seed(s)
    tf.random.set_seed(s)

def compute_mape(y_true, y_pred):
    y_true = np.array(y_true).astype(float)
    y_pred = np.array(y_pred).astype(float)
    mask = y_true != 0
    if np.any(mask):
        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0
    else:
        return np.nan

def build_lstm_model(input_shape, units=16, dropout=0.01, lr=1e-3):
    K.clear_session()
    model = Sequential()
    model.add(LSTM(units=units, input_shape=input_shape))
    if dropout > 0:
        model.add(Dropout(dropout))
    model.add(Dense(1, activation='linear'))
    model.compile(optimizer=Adam(learning_rate=lr), loss='mse')
    return model

def make_sequences(X_scaled, y_scaled, window):
    X_seq, y_seq = [], []
    for i in range(window, len(X_scaled)):
        X_seq.append(X_scaled[i-window:i])
        y_seq.append(y_scaled[i])
    X_seq = np.array(X_seq)
    y_seq = np.array(y_seq)
    return X_seq, y_seq

def load_sample_data():
    """Load sample data for demonstration"""
    try:
        # Download sample data
        ticker = "TLKM.JK"
        end_date = pd.Timestamp.now()
        start_date = end_date - pd.DateOffset(months=24)
        df = yf.download(ticker, start=start_date, end=end_date)
        return df
    except:
        # Fallback: create sample data
        dates = pd.date_range(start='2020-01-01', end='2024-01-01', freq='D')
        np.random.seed(42)
        prices = 4000 + np.cumsum(np.random.randn(len(dates)) * 50)
        df = pd.DataFrame({'Close': prices}, index=dates)
        return df

def main():
    st.title("üìà Stock Price Prediction with LSTM-PSO")
    st.markdown("Prediksi harga saham menggunakan model LSTM yang dioptimasi dengan Particle Swarm Optimization")

    # Sidebar
    st.sidebar.header("Configuration")

    # Data source selection
    data_source = st.sidebar.radio(
        "Data Source",
        ["Upload Excel File", "Yahoo Finance Ticker", "Use Sample Data"]
    )

    df = None

    if data_source == "Upload Excel File":
        uploaded_file = st.sidebar.file_uploader("Upload Excel File", type=['xlsx'])
        if uploaded_file:
            df = pd.read_excel(uploaded_file)
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df = df.sort_values('Date')
                df.set_index('Date', inplace=True)

    elif data_source == "Yahoo Finance Ticker":
        ticker = st.sidebar.text_input("Stock Ticker", "TLKM.JK")
        if st.sidebar.button("Download Data"):
            with st.spinner("Downloading data..."):
                try:
                    df = yf.download(ticker, period="2y")
                    st.sidebar.success(f"Data for {ticker} downloaded successfully!")
                except Exception as e:
                    st.sidebar.error(f"Error downloading data: {e}")

    else:  # Use Sample Data
        if st.sidebar.button("Load Sample Data"):
            with st.spinner("Loading sample data..."):
                df = load_sample_data()
                st.sidebar.success("Sample data loaded successfully!")

    # Display data if loaded
    if df is not None and not df.empty:
        st.session_state.data_loaded = True

        col1, col2 = st.columns([2, 1])

        with col1:
            st.subheader("Data Preview")
            st.dataframe(df.head(), use_container_width=True)

            # Plot original data
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.plot(df.index, df['Close'], label='Close Price', linewidth=1)
            ax.set_title("Stock Price Time Series")
            ax.set_xlabel("Date")
            ax.set_ylabel("Price")
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

        with col2:
            st.subheader("Data Info")
            st.write(f"**Period:** {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}")
            st.write(f"**Total Records:** {len(df)}")
            st.write(f"**Missing Values:** {df['Close'].isnull().sum()}")

            # Basic statistics
            st.write("**Statistics:**")
            st.write(f"Mean: {df['Close'].mean():.2f}")
            st.write(f"Std: {df['Close'].std():.2f}")
            st.write(f"Min: {df['Close'].min():.2f}")
            st.write(f"Max: {df['Close'].max():.2f}")

        # Model training section
        st.markdown("---")
        st.header("Model Training")

        training_col1, training_col2 = st.columns([1, 1])

        with training_col1:
            st.subheader("Training Configuration")
            lookback_days = st.slider("Lookback Days", 1, 60, 1)
            train_test_split = st.slider("Train-Test Split (%)", 70, 90, 80)
            run_pso = st.checkbox("Enable PSO Optimization", value=True)

            if st.button("Train Model", type="primary"):
                with st.spinner("Training model... This may take several minutes"):
                    try:
                        # Preprocessing
                        feature_cols = ["Close"]
                        target_col = "Close"

                        data_features = df[feature_cols].values
                        data_target = df[[target_col]].values

                        n = len(df)
                        n_train = int(n * (train_test_split / 100))
                        n_test = n - n_train

                        # Fit scalers on training data only
                        scaler_X = MinMaxScaler().fit(data_features[:n_train])
                        scaler_y = MinMaxScaler().fit(data_target[:n_train])

                        Xs = scaler_X.transform(data_features)
                        ys = scaler_y.transform(data_target)

                        # Create sequences
                        X_seq_all, y_seq_all = make_sequences(Xs, ys, window=lookback_days)
                        train_end_idx = n_train - lookback_days

                        if train_end_idx <= 0:
                            st.error("Lookback window too large for training data. Please reduce lookback days.")
                            return

                        X_train = X_seq_all[:train_end_idx]
                        y_train = y_seq_all[:train_end_idx]
                        X_test = X_seq_all[train_end_idx:]
                        y_test = y_seq_all[train_end_idx:]

                        # Store in session state
                        st.session_state.X_train = X_train
                        st.session_state.y_train = y_train
                        st.session_state.X_test = X_test
                        st.session_state.y_test = y_test
                        st.session_state.scaler_X = scaler_X
                        st.session_state.scaler_y = scaler_y
                        st.session_state.lookback_days = lookback_days

                        # Baseline model
                        st.subheader("Baseline LSTM Model")
                        progress_bar = st.progress(0)

                        set_seed(42)
                        model_base = build_lstm_model(
                            input_shape=(X_train.shape[1], X_train.shape[2]),
                            units=BASE_UNITS,
                            dropout=BASE_DROPOUT,
                            lr=BASE_LR
                        )

                        # Train baseline model
                        history_base = model_base.fit(
                            X_train, y_train,
                            epochs=BASE_EPOCHS,
                            batch_size=BASE_BATCH,
                            validation_split=0.2,
                            verbose=0
                        )

                        progress_bar.progress(50)

                        # Evaluate baseline
                        y_pred_scaled_base = model_base.predict(X_test, verbose=0)
                        y_pred_base = scaler_y.inverse_transform(y_pred_scaled_base).flatten()
                        y_true_base = scaler_y.inverse_transform(y_test).flatten()

                        mse_base = mean_squared_error(y_true_base, y_pred_base)
                        mape_base = compute_mape(y_true_base, y_pred_base)

                        st.session_state.baseline_results = {
                            'mse': mse_base,
                            'mape': mape_base,
                            'predictions': y_pred_base,
                            'actual': y_true_base
                        }

                        st.success("Baseline model trained successfully!")

                        if run_pso:
                            st.subheader("PSO Optimization")
                            pso_progress = st.progress(0)

                            # PSO objective function - FIXED VERSION
                            def make_pso_obj(X_tr, y_tr, X_va, y_va, scaler_y):
                                def obj_fn(particles):
                                    n_particles = particles.shape[0]
                                    costs = np.full(n_particles, 1e12)  # PASTIKAN SELALU 10 VALUES
                                    
                                    for i in range(n_particles):
                                        try:
                                            p = particles[i]
                                            # Parameter extraction dengan clamping yang lebih ketat
                                            units = int(np.clip(np.round(p[0]), 16, 64))
                                            lr = float(np.clip(p[1], 1e-4, 1e-2))
                                            batch = int(np.clip(np.round(p[2]), 16, 64))
                                            dropout = float(np.clip(p[3], 0.0, 0.2))
                                            
                                            # Build simple model
                                            K.clear_session()
                                            model = Sequential([
                                                LSTM(units, input_shape=(X_tr.shape[1], X_tr.shape[2])),
                                                Dropout(dropout),
                                                Dense(1)
                                            ])
                                            model.compile(optimizer=Adam(learning_rate=lr), loss='mse')
                                            
                                            # Quick training
                                            model.fit(
                                                X_tr, y_tr,
                                                epochs=3,
                                                batch_size=batch,
                                                validation_data=(X_va, y_va),
                                                verbose=0,
                                                shuffle=False
                                            )
                                            
                                            # Prediction
                                            yv_pred = model.predict(X_va, verbose=0)
                                            
                                            # Ensure same dimensions
                                            if yv_pred.shape[0] == y_va.shape[0]:
                                                yv_pred_orig = scaler_y.inverse_transform(yv_pred).flatten()
                                                yv_true_orig = scaler_y.inverse_transform(y_va).flatten()
                                                
                                                if len(yv_true_orig) > 0 and len(yv_pred_orig) > 0:
                                                    costs[i] = mean_squared_error(yv_true_orig, yv_pred_orig)
                                                else:
                                                    costs[i] = 1e12
                                            else:
                                                costs[i] = 1e12
                                                
                                        except Exception as e:
                                            costs[i] = 1e12
                                            continue
                                            
                                    return costs  # PASTI return array dengan 10 elements
                                    
                                return obj_fn

                            # Validasi data sebelum PSO
                            if 'X_train' not in st.session_state:
                                st.error("‚ùå Training data tidak tersedia!")
                                return
                                
                            X_train = st.session_state.X_train
                            y_train = st.session_state.y_train
                            
                            if len(X_train) < 20:
                                st.error(f"‚ùå Data training terlalu sedikit: {len(X_train)} samples")
                                return

                            # PREPARE PSO DATA - FIXED VERSION
                            # Gunakan approach yang lebih sederhana dan robust
                            total_samples = len(X_train)
                            train_size = max(1, int(0.8 * total_samples))  # 80% for training
                            
                            X_tr_for_pso = X_train[:train_size]
                            y_tr_for_pso = y_train[:train_size]
                            X_val_for_pso = X_train[train_size:]
                            y_val_for_pso = y_train[train_size:]
                            
                            # Fallback jika validation data kosong
                            if len(X_val_for_pso) == 0:
                                # Use last 10 samples for validation
                                val_size = min(10, total_samples - 1)
                                X_tr_for_pso = X_train[:-val_size]
                                y_tr_for_pso = y_train[:-val_size]
                                X_val_for_pso = X_train[-val_size:]
                                y_val_for_pso = y_train[-val_size:]
                            
                            st.info(f"üîß PSO Data: Train={len(X_tr_for_pso)}, Val={len(X_val_for_pso)}")

                            # Validasi final
                            if len(X_val_for_pso) == 0:
                                st.error("‚ùå Tidak ada data validation untuk PSO!")
                                return

                            pso_obj = make_pso_obj(
                                X_tr_for_pso, y_tr_for_pso,
                                X_val_for_pso, y_val_for_pso,
                                st.session_state.scaler_y
                            )

                            # Run PSO dengan error handling
                            try:
                                optimizer = GlobalBestPSO(
                                    n_particles=PSO_N_PARTICLES,
                                    dimensions=4,
                                    options=PSO_OPTIONS,
                                    bounds=PSO_BOUNDS
                                )

                                # PSO iterations
                                history_gbest_cost = []
                                
                                for it in range(PSO_ITERS):
                                    # Panggil objective function
                                    costs = pso_obj(optimizer.swarm.position)
                                    
                                    # DEBUG: Check costs shape
                                    if len(costs) != PSO_N_PARTICLES:
                                        st.error(f"‚ùå Costs shape error: {costs.shape}, expected {PSO_N_PARTICLES}")
                                        break
                                    
                                    # Update PSO
                                    mask = costs < optimizer.swarm.pbest_cost
                                    optimizer.swarm.pbest_cost[mask] = costs[mask]
                                    optimizer.swarm.pbest_pos[mask] = optimizer.swarm.position[mask].copy()
                                    
                                    best_idx = np.argmin(optimizer.swarm.pbest_cost)
                                    optimizer.swarm.best_cost = optimizer.swarm.pbest_cost[best_idx]
                                    optimizer.swarm.best_pos = optimizer.swarm.pbest_pos[best_idx].copy()
                                    
                                    history_gbest_cost.append(float(optimizer.swarm.best_cost))
                                    
                                    # Update velocity and position
                                    r1 = np.random.rand(*optimizer.swarm.position.shape)
                                    r2 = np.random.rand(*optimizer.swarm.position.shape)
                                    optimizer.swarm.velocity = (
                                        PSO_OPTIONS['w'] * optimizer.swarm.velocity +
                                        PSO_OPTIONS['c1'] * r1 * (optimizer.swarm.pbest_pos - optimizer.swarm.position) +
                                        PSO_OPTIONS['c2'] * r2 * (optimizer.swarm.best_pos - optimizer.swarm.position)
                                    )
                                    optimizer.swarm.position += optimizer.swarm.velocity
                                    
                                    # Clip to bounds
                                    lb, ub = np.array(PSO_BOUNDS[0]), np.array(PSO_BOUNDS[1])
                                    optimizer.swarm.position = np.clip(optimizer.swarm.position, lb, ub)
                                    
                                    pso_progress.progress((it + 1) / PSO_ITERS)

                                # Cek apakah PSO berhasil
                                if len(history_gbest_cost) == 0:
                                    st.error("‚ùå PSO gagal total!")
                                    return
                                    
                                # Get best parameters
                                best_pos = optimizer.swarm.best_pos
                                best_units = int(np.clip(np.round(best_pos[0]), 16, 64))
                                best_lr = float(np.clip(best_pos[1], 1e-4, 1e-2))
                                best_batch = int(np.clip(np.round(best_pos[2]), 16, 64))
                                best_dropout = float(np.clip(best_pos[3], 0.0, 0.2))

                                st.session_state.pso_results = {
                                    'best_units': best_units,
                                    'best_lr': best_lr,
                                    'best_batch': best_batch,
                                    'best_dropout': best_dropout,
                                    'best_cost': history_gbest_cost[-1],
                                    'convergence': history_gbest_cost
                                }

                                st.success(f"‚úÖ PSO Completed! Best Val Loss: {history_gbest_cost[-1]:.6f}")

                                # Train final model with PSO parameters
                                st.subheader("Final PSO-LSTM Model")
                                final_progress = st.progress(0)

                                set_seed(42)
                                model_final = build_lstm_model(
                                    input_shape=(X_train.shape[1], X_train.shape[2]),
                                    units=best_units,
                                    dropout=best_dropout,
                                    lr=best_lr
                                )

                                history_final = model_final.fit(
                                    X_train, y_train,
                                    epochs=100,
                                    batch_size=best_batch,
                                    validation_split=0.2,
                                    callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)],
                                    verbose=0
                                )

                                final_progress.progress(100)

                                # Evaluate final model
                                y_pred_scaled_final = model_final.predict(X_test, verbose=0)
                                y_pred_final = scaler_y.inverse_transform(y_pred_scaled_final).flatten()
                                y_true_final = scaler_y.inverse_transform(y_test).flatten()

                                mse_final = mean_squared_error(y_true_final, y_pred_final)
                                mape_final = compute_mape(y_true_final, y_pred_final)

                                st.session_state.final_results = {
                                    'mse': mse_final,
                                    'mape': mape_final,
                                    'predictions': y_pred_final,
                                    'actual': y_true_final,
                                    'history': history_final.history,
                                    'model': model_final
                                }

                                st.session_state.model_trained = True
                                st.success("PSO-LSTM model trained successfully!")

                            except Exception as e:
                                st.error(f"‚ùå PSO Error: {str(e)}")

                    except Exception as e:
                        st.error(f"Error during training: {str(e)}")

        with training_col2:
            if st.session_state.get('model_trained', False):
                st.subheader("Training Results")

                # Display metrics
                baseline_results = st.session_state.baseline_results
                col_metric1, col_metric2 = st.columns(2)

                with col_metric1:
                    st.metric("Baseline MSE", f"{baseline_results['mse']:.6f}")
                    st.metric("Baseline MAPE", f"{baseline_results['mape']:.4f}%")

                if 'final_results' in st.session_state:
                    final_results = st.session_state.final_results
                    pso_results = st.session_state.pso_results

                    with col_metric2:
                        st.metric("PSO-LSTM MSE", f"{final_results['mse']:.6f}")
                        st.metric("PSO-LSTM MAPE", f"{final_results['mape']:.4f}%")

                    # Improvement
                    impr_mse = (baseline_results['mse'] - final_results['mse']) / baseline_results['mse'] * 100
                    impr_mape = (baseline_results['mape'] - final_results['mape']) / baseline_results['mape'] * 100

                    st.info(f"Improvement: MSE ‚Üì {impr_mse:.2f}%, MAPE ‚Üì {impr_mape:.2f}%")

                    # PSO parameters
                    st.subheader("PSO Optimized Parameters")
                    st.write(f"**Units:** {pso_results['best_units']}")
                    st.write(f"**Learning Rate:** {pso_results['best_lr']:.6f}")
                    st.write(f"**Batch Size:** {pso_results['best_batch']}")
                    st.write(f"**Dropout:** {pso_results['best_dropout']:.4f}")

        # Results visualization
        if st.session_state.get('model_trained', False):
            st.markdown("---")
            st.header("Results Visualization")

            tab1, tab2, tab3 = st.tabs(["Predictions", "Training History", "Forecast"])

            with tab1:
                fig, ax = plt.subplots(figsize=(12, 6))
                actual = st.session_state.baseline_results['actual']

                ax.plot(actual, label='Actual', linewidth=2, color='blue')
                ax.plot(st.session_state.baseline_results['predictions'],
                       label='Baseline LSTM', linewidth=2, color='red', linestyle='--')

                if 'final_results' in st.session_state:
                    ax.plot(st.session_state.final_results['predictions'],
                           label='PSO-LSTM', linewidth=2, color='orange')

                ax.set_title("Actual vs Predicted Prices")
                ax.set_xlabel("Time Index")
                ax.set_ylabel("Price")
                ax.legend()
                ax.grid(True, alpha=0.3)
                st.pyplot(fig)

            with tab2:
                if 'final_results' in st.session_state:
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

                    # Baseline training history
                    ax1.plot(st.session_state.baseline_results.get('history', {}).get('loss', []),
                            label='Training Loss')
                    ax1.plot(st.session_state.baseline_results.get('history', {}).get('val_loss', []),
                            label='Validation Loss')
                    ax1.set_title("Baseline LSTM Training History")
                    ax1.set_xlabel("Epoch")
                    ax1.set_ylabel("Loss")
                    ax1.legend()
                    ax1.grid(True, alpha=0.3)

                    # PSO-LSTM training history
                    ax2.plot(st.session_state.final_results['history']['loss'],
                            label='Training Loss')
                    ax2.plot(st.session_state.final_results['history']['val_loss'],
                            label='Validation Loss')
                    ax2.set_title("PSO-LSTM Training History")
                    ax2.set_xlabel("Epoch")
                    ax2.set_ylabel("Loss")
                    ax2.legend()
                    ax2.grid(True, alpha=0.3)

                    st.pyplot(fig)

            with tab3:
                if 'final_results' in st.session_state:
                    st.subheader("Future Price Forecast")
                    n_forecast = st.slider("Days to Forecast", 1, 30, 5)

                    if st.button("Generate Forecast"):
                        with st.spinner("Generating forecast..."):
                            try:
                                model_final = st.session_state.final_results['model']
                                scaler_X = st.session_state.scaler_X
                                scaler_y = st.session_state.scaler_y
                                lookback_days = st.session_state.lookback_days
                                data_features = df[['Close']].values

                                # Prepare last window
                                last_window_raw = data_features[-lookback_days:]
                                last_window_scaled = scaler_X.transform(last_window_raw).reshape(1, lookback_days, 1)

                                # Generate forecast
                                forecast_scaled = []
                                curr_input = last_window_scaled.copy()

                                for i in range(n_forecast):
                                    pred_s = model_final.predict(curr_input, verbose=0)[0,0]
                                    forecast_scaled.append(pred_s)
                                    new_step = np.array(pred_s).reshape(1,1,1)
                                    curr_input = np.concatenate([curr_input[:,1:,:], new_step], axis=1)

                                # Inverse transform
                                forecast_scaled_arr = np.array(forecast_scaled).reshape(-1,1)
                                forecast_inv = scaler_y.inverse_transform(forecast_scaled_arr).flatten()

                                # Create future dates
                                last_date = df.index[-1]
                                future_dates = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=n_forecast)

                                # Display forecast
                                forecast_df = pd.DataFrame({
                                    'Date': future_dates,
                                    'Forecasted Price': forecast_inv
                                })

                                st.dataframe(forecast_df.style.format({'Forecasted Price': '{:.2f}'}))

                                # Plot forecast
                                fig, ax = plt.subplots(figsize=(12, 6))

                                # Historical data (last 100 days)
                                historical_dates = df.index[-100:]
                                historical_prices = df['Close'].values[-100:]

                                ax.plot(historical_dates, historical_prices,
                                       label='Historical', color='steelblue', linewidth=2)
                                ax.plot(future_dates, forecast_inv,
                                       label='Forecast', color='orange', marker='o', linewidth=2)

                                # Connecting line
                                ax.plot([historical_dates[-1], future_dates[0]],
                                       [historical_prices[-1], forecast_inv[0]],
                                       color='orange', linestyle='--', alpha=0.7)

                                ax.set_title(f"{n_forecast}-Day Price Forecast")
                                ax.set_xlabel("Date")
                                ax.set_ylabel("Price")
                                ax.legend()
                                ax.grid(True, alpha=0.3)
                                plt.xticks(rotation=45)
                                st.pyplot(fig)

                            except Exception as e:
                                st.error(f"Error generating forecast: {str(e)}")

    else:
        st.info("üëà Please load data using the sidebar options to get started.")

        # Quick start guide
        st.markdown("---")
        st.subheader("Quick Start Guide")

        col_guide1, col_guide2, col_guide3 = st.columns(3)

        with col_guide1:
            st.write("**1. Choose Data Source**")
            st.write("Upload Excel file or use Yahoo Finance")

        with col_guide2:
            st.write("**2. Configure Model**")
            st.write("Set lookback days and training parameters")

        with col_guide3:
            st.write("**3. Train & Predict**")
            st.write("Run training and view predictions")

if __name__ == "__main__":
    main() 
